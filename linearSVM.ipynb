{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn import metrics\n",
    "from numpy import genfromtxt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load yelp Binary BOW\n",
    "\n",
    "training_yelp_feat_bin= genfromtxt('./Bin_BoW/yelp/trainig_yelp_feat_bin.txt', delimiter=',')\n",
    "target_training_yelp_bin= genfromtxt('./Bin_BoW/yelp/target_training_yelp_bin.txt', delimiter=',')\n",
    "\n",
    "valid_yelp_feat_bin= genfromtxt('./Bin_BoW/yelp/valid_yelp_feat_bin.txt', delimiter=',')\n",
    "target_valid_yelp_bin= genfromtxt('./Bin_BoW/yelp/target_valid_yelp_bin.txt', delimiter=',')\n",
    "\n",
    "test_yelp_feat_bin= genfromtxt('./Bin_BoW/yelp/test_yelp_feat_bin.txt', delimiter=',')\n",
    "target_test_yelp_bin= genfromtxt('./Bin_BoW/yelp/target_test_yelp_bin.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=700, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=svm.SVC(kernel='linear', C=100, verbose=1, max_iter=700)\n",
    "clf.fit(training_yelp_feat_bin,target_training_yelp_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure Training set_SVM_yelp:\n",
      "0.732727093647\n"
     ]
    }
   ],
   "source": [
    "print \"F-measure Training set_SVM_yelp:\"\n",
    "Y_out=clf.predict(training_yelp_feat_bin)\n",
    "print metrics.f1_score(target_training_yelp_bin, Y_out, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure Validation set_SVM_yelp:\n",
      "0.388037211881\n"
     ]
    }
   ],
   "source": [
    "print \"F-measure Validation set_SVM_yelp:\"\n",
    "Y_out=clf.predict(valid_yelp_feat_bin)\n",
    "print metrics.f1_score(target_valid_yelp_bin, Y_out, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure Test set_SVM_yelp:\n",
      "0.401466020809\n"
     ]
    }
   ],
   "source": [
    "print \"F-measure Test set_SVM_yelp:\"\n",
    "Y_out=clf.predict(test_yelp_feat_bin)\n",
    "print metrics.f1_score(target_test_yelp_bin, Y_out, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load yelp Freqency BOW\n",
    "\n",
    "training_yelp_feat_freq= genfromtxt('./freq_BoW/yelp/trainig_yelp_feat_freq.txt', delimiter=',')\n",
    "target_training_yelp_freq= genfromtxt('./freq_BoW/yelp/target_training_yelp_freq.txt', delimiter=',')\n",
    "\n",
    "valid_yelp_feat_freq= genfromtxt('./freq_BoW/yelp/valid_yelp_fea_freq.txt', delimiter=',')\n",
    "target_valid_yelp_freq= genfromtxt('./freq_BoW/yelp/target_valid_yelp_freq.txt', delimiter=',')\n",
    "\n",
    "test_yelp_feat_freq= genfromtxt('./freq_BoW/yelp/test_yelp_feat_freq.txt', delimiter=',')\n",
    "target_test_yelp_freq= genfromtxt('./freq_BoW/yelp/target_test_yelp_freq.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_yelp_feat_freq=np.nan_to_num(training_yelp_feat_freq)\n",
    "test_yelp_feat_freq=np.nan_to_num(test_yelp_feat_freq)\n",
    "valid_yelp_feat_freq=np.nan_to_num(valid_yelp_feat_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=700, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=svm.SVC(kernel='linear', C=1000, verbose=1, max_iter=700)\n",
    "clf.fit(training_yelp_feat_freq,target_training_yelp_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure Training set_SVM_yelp:\n",
      "0.693183390737\n"
     ]
    }
   ],
   "source": [
    "print \"F-measure Training set_SVM_yelp:\"\n",
    "Y_out=clf.predict(training_yelp_feat_freq)\n",
    "print metrics.f1_score(target_training_yelp_freq, Y_out, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure Validation set_SVM_yelp:\n",
      "0.409865904388\n"
     ]
    }
   ],
   "source": [
    "print \"F-measure Validation set_SVM_yelp:\"\n",
    "Y_out=clf.predict(valid_yelp_feat_freq)\n",
    "print metrics.f1_score(target_valid_yelp_freq, Y_out, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure Test set_SVM_yelp:\n",
      "0.375082686037\n"
     ]
    }
   ],
   "source": [
    "print \"F-measure Test set_SVM_yelp:\"\n",
    "Y_out=clf.predict(test_yelp_feat_freq)\n",
    "print metrics.f1_score(target_test_yelp_freq, Y_out, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################IMDB_BINARY Bag of Words##############################\n",
    "#########################################################Training set######################################\n",
    "import csv\n",
    "reader_feature = csv.reader(open('./Bin_BoW/IMDB/trainig_IMDB_feat_bin.txt'))\n",
    "reader_target = csv.reader(open('./Bin_BoW/IMDB/target_training_IMDB_bin.txt'))\n",
    "\n",
    "i=0\n",
    "j=0\n",
    "training_IMDB_feat_bin=[]\n",
    "target_training_IMDB_bin=[]\n",
    "\n",
    "for row in reader_feature:\n",
    "    training_IMDB_feat_bin.append(row)\n",
    "    i=i+1\n",
    "    \n",
    "for row in reader_target:\n",
    "    target_training_IMDB_bin.append(row)\n",
    "    j=j+1\n",
    "    \n",
    "training_IMDB_feat_bin = np.asarray(training_IMDB_feat_bin, dtype=float)\n",
    "target_training_IMDB_bin = np.asarray(target_training_IMDB_bin, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################IMDB_BINARY Bag of Words##############################\n",
    "#########################################################validation set######################################\n",
    "import csv\n",
    "reader_feature = csv.reader(open('./Bin_BoW/IMDB/valid_IMDB_feat_bin.txt'))\n",
    "reader_target = csv.reader(open('./Bin_BoW/IMDB/target_valid_IMDB_bin.txt'))\n",
    "i=0\n",
    "j=0\n",
    "valid_IMDB_feat_bin=[]\n",
    "target_valid_IMDB_bin=[]\n",
    "\n",
    "for row in reader_feature:\n",
    "    valid_IMDB_feat_bin.append(row)\n",
    "    i=i+1\n",
    "    \n",
    "for row in reader_target:\n",
    "    target_valid_IMDB_bin.append(row)\n",
    "    j=j+1\n",
    "    \n",
    "valid_IMDB_feat_bin = np.asarray(valid_IMDB_feat_bin, dtype=float)\n",
    "target_valid_IMDB_bin = np.asarray(target_valid_IMDB_bin, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=700, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=svm.SVC(kernel='linear', C=1000, verbose=1, max_iter=700)\n",
    "clf.fit(training_IMDB_feat_bin,target_training_IMDB_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure Training set_SVM_IMDB:\n",
      "0.787513632446\n",
      "F-measure Validation set_SVM_IMDB:\n",
      "0.746920659404\n"
     ]
    }
   ],
   "source": [
    "print \"F-measure Training set_SVM_IMDB:\"\n",
    "Y_out=clf.predict(training_IMDB_feat_bin)\n",
    "print metrics.f1_score(target_training_IMDB_bin, Y_out, average='macro')\n",
    "\n",
    "print \"F-measure Validation set_SVM_IMDB:\"\n",
    "Y_out=clf.predict(valid_IMDB_feat_bin)\n",
    "print metrics.f1_score(target_valid_IMDB_bin, Y_out, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################IMDB_BINARY Bag of Words##############################\n",
    "#########################################################test set######################################\n",
    "\n",
    "import csv\n",
    "reader_feature = csv.reader(open('./Bin_BoW/IMDB/test_IMDB_feat_bin.txt'))\n",
    "reader_target = csv.reader(open('./Bin_BoW/IMDB/target_test_IMDB_bin.txt'))\n",
    "\n",
    "i=0\n",
    "j=0\n",
    "test_IMDB_feat_bin=[]\n",
    "target_test_IMDB_bin=[]\n",
    "\n",
    "for row in reader_feature:\n",
    "    test_IMDB_feat_bin.append(row)\n",
    "    i=i+1\n",
    "    \n",
    "for row in reader_target:\n",
    "    target_test_IMDB_bin.append(row)\n",
    "    j=j+1\n",
    "    \n",
    "test_IMDB_feat_bin = np.asarray(test_IMDB_feat_bin, dtype=float)\n",
    "target_test_IMDB_bin = np.asarray(target_test_IMDB_bin, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure test set_SVM_IMDB:\n",
      "0.739886547813\n"
     ]
    }
   ],
   "source": [
    "print \"F-measure test set_SVM_IMDB:\"\n",
    "Y_out=clf.predict(test_IMDB_feat_bin)\n",
    "print metrics.f1_score(target_test_IMDB_bin, Y_out, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################IMDB_frequency Bag of Words##############################\n",
    "#########################################################Training set######################################\n",
    "import csv\n",
    "reader_feature = csv.reader(open('./freq_BoW/IMDB/trainig_IMDB_feat_freq.txt'))\n",
    "reader_target = csv.reader(open('./freq_BoW/IMDB/target_training_IMDB_freq.txt'))\n",
    "\n",
    "i=0\n",
    "j=0\n",
    "training_IMDB_feat_freq=[]\n",
    "target_training_IMDB_freq=[]\n",
    "\n",
    "for row in reader_feature:\n",
    "    training_IMDB_feat_freq.append(row)\n",
    "    i=i+1\n",
    "    \n",
    "for row in reader_target:\n",
    "    target_training_IMDB_freq.append(row)\n",
    "    j=j+1\n",
    "    \n",
    "training_IMDB_feat_freq = np.asarray(training_IMDB_feat_freq, dtype=float)\n",
    "target_training_IMDB_freq = np.asarray(target_training_IMDB_freq, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################IMDB_frequency Bag of Words##############################\n",
    "#########################################################validation set######################################\n",
    "import csv\n",
    "reader_feature = csv.reader(open('./freq_BoW/IMDB/valid_IMDB_fea_freq.txt'))\n",
    "reader_target = csv.reader(open('./freq_BoW/IMDB/target_valid_IMDB_freq.txt'))\n",
    "i=0\n",
    "j=0\n",
    "valid_IMDB_feat_freq=[]\n",
    "target_valid_IMDB_freq=[]\n",
    "\n",
    "for row in reader_feature:\n",
    "    valid_IMDB_feat_freq.append(row)\n",
    "    i=i+1\n",
    "    \n",
    "for row in reader_target:\n",
    "    target_valid_IMDB_freq.append(row)\n",
    "    j=j+1\n",
    "    \n",
    "valid_IMDB_feat_freq = np.asarray(valid_IMDB_feat_freq, dtype=float)\n",
    "target_valid_IMDB_freq = np.asarray(target_valid_IMDB_freq, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=700, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=svm.SVC(kernel='linear', C=1, verbose=1, max_iter=700, decision_function_shape='ovr')\n",
    "clf.fit(training_IMDB_feat_freq,target_training_IMDB_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure Training set_SVM_IMDB:\n",
      "0.395516211866\n"
     ]
    }
   ],
   "source": [
    "print \"F-measure Training set_SVM_IMDB:\"\n",
    "Y_out=clf.predict(training_IMDB_feat_freq)\n",
    "print metrics.f1_score(target_training_IMDB_freq, Y_out, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure Validation set_SVM_IMDB:\n",
      "0.394701100607\n"
     ]
    }
   ],
   "source": [
    "print \"F-measure Validation set_SVM_IMDB:\"\n",
    "Y_out=clf.predict(valid_IMDB_feat_freq)\n",
    "print metrics.f1_score(target_valid_IMDB_freq, Y_out, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################IMDB_freq Bag of Words##############################\n",
    "#########################################################test set######################################\n",
    "\n",
    "import csv\n",
    "reader_feature = csv.reader(open('./freq_BoW/IMDB/test_IMDB_feat_freq.txt'))\n",
    "reader_target = csv.reader(open('./freq_BoW/IMDB/target_test_IMDB_freq.txt'))\n",
    "\n",
    "i=0\n",
    "j=0\n",
    "test_IMDB_feat_freq=[]\n",
    "target_test_IMDB_freq=[]\n",
    "\n",
    "for row in reader_feature:\n",
    "    test_IMDB_feat_freq.append(row)\n",
    "    i=i+1\n",
    "    \n",
    "for row in reader_target:\n",
    "    target_test_IMDB_freq.append(row)\n",
    "    j=j+1\n",
    "    \n",
    "test_IMDB_feat_freq = np.asarray(test_IMDB_feat_freq, dtype=float)\n",
    "target_test_IMDB_freq = np.asarray(target_test_IMDB_freq, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure test set_SVM_IMDB:\n",
      "0.402275422842\n"
     ]
    }
   ],
   "source": [
    "print \"F-measure test set_SVM_IMDB:\"\n",
    "Y_out=clf.predict(test_IMDB_feat_freq)\n",
    "print metrics.f1_score(target_test_IMDB_freq, Y_out, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
